<!DOCTYPE html>
<html>
<head>
    <title>Sports vs Politics Text Classification</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>

<div class="container">

<h1>Sports vs Politics Text Classification</h1>
<p class="subtitle">Natural Language Understanding Assignment</p>
<p><b>Author:</b> Vishal | Roll No: B23CM1048</p>

<div class="card">
<h2>Abstract</h2>
<p>
This project presents a comparative study of classical machine learning techniques 
for binary text classification of news articles into Sports and Politics categories. 
Two datasets with different characteristics were used: the BBC News dataset (clean and structured) 
and the AG News dataset (larger and more diverse). The objective was to evaluate 
model performance, robustness, and generalization capability across datasets 
with varying complexity.
</p>
</div>

<div class="card">
<h2>ðŸ“‚ Data Collection</h2>
<p>
The BBC dataset was collected in folder format, containing separate directories 
for Sports and Politics articles. Each article was stored as a text file.
</p>

<p>
The AG News dataset was downloaded in CSV format and filtered to include 
only the World (relabelled as Politics) and Sports categories.
</p>

<ul>
<li><b>BBC Dataset:</b> 928 articles (511 Sports, 417 Politics)</li>
<li><b>AG News Dataset:</b> ~11,400 filtered samples</li>
</ul>
</div>

<div class="card">
<h2> Dataset Analysis</h2>
<p>
The BBC dataset contains longer, professionally written articles with strong lexical separation 
between domains. Sports articles frequently include terms such as "match", "team", and "season", 
while political articles include terms like "government", "election", and "policy".
</p>

<p>
In contrast, AG News articles are shorter and exhibit greater vocabulary overlap. 
This increases classification complexity and better represents real-world news scenarios.
</p>
</div>

<div class="card">
<h2> Methodology</h2>
<p>
Text preprocessing involved lowercasing and stopword removal. 
Documents were converted into numerical feature vectors using TF-IDF representation, 
which balances term frequency and inverse document frequency.
</p>

<p>
Three models were evaluated:
</p>

<ul>
<li>Naive Bayes (Probabilistic Model)</li>
<li>Logistic Regression (Discriminative Linear Model)</li>
<li>Support Vector Machine (Margin-based Classifier)</li>
</ul>

<p>
An 80â€“20 stratified train-test split was applied to the BBC dataset, 
while AG News used predefined splits. Evaluation metrics included accuracy, 
precision, recall, and F1-score.
</p>
</div>

<div class="card">
<h2>Experimental Results</h2>

<h3>BBC Dataset</h3>
<table>
<tr><th>Model</th><th>Accuracy</th></tr>
<tr><td>Naive Bayes</td><td>1.000</td></tr>
<tr><td>Logistic Regression</td><td>1.000</td></tr>
<tr><td>SVM</td><td>1.000</td></tr>
</table>

<h3>AG News Dataset</h3>
<table>
<tr><th>Model</th><th>Accuracy</th></tr>
<tr><td>Naive Bayes</td><td>0.9739</td></tr>
<tr><td>Logistic Regression</td><td>0.9774</td></tr>
<tr><td>SVM</td><td>0.9761</td></tr>
</table>

<p>
All models achieved perfect accuracy on the BBC dataset due to strong topic separation. 
On the AG dataset, performance slightly decreased due to vocabulary overlap and shorter context.
</p>

</div>

<div class="card">
<h2>Model Comparison Chart</h2>
<img src="assets/comparison.png" alt="Model Comparison Chart" class="chart">
</div>

<div class="card">
<h2>Precision & Recall </h2>
<img src="assets/Precision-Recall.png" alt="Precision & Recall" class="chart">
</div>

<div class="card">
<h2>Discussion</h2>
<p>
The comparative analysis demonstrates that classical machine learning models 
remain highly effective for structured topic classification tasks. However, 
performance varies depending on dataset characteristics. Logistic Regression 
performed marginally better on the AG dataset, indicating that discriminative 
models may better handle overlapping feature distributions.
</p>
</div>

<div class="card">
<h2>Challenges and Limitations</h2>
<ul>
<li>TF-IDF ignores semantic meaning and word order.</li>
<li>Binary classification oversimplifies multi-topic news articles.</li>
<li>Models do not capture contextual dependencies.</li>
<li>Dataset domain shift affects generalization.</li>
</ul>
</div>

<div class="card">
<h2>Future Work</h2>
<ul>
<li>Use word embeddings (Word2Vec, GloVe).</li>
<li>Apply transformer-based models (BERT).</li>
<li>Extend to multi-class classification.</li>
<li>Perform cross-validation for stronger evaluation.</li>
</ul>
</div>

<div class="card">
<h2>Project Resources</h2>
<p>
<a href="report/Report.pdf" target="_blank">Download Full Report (PDF)</a>
</p>
<p>
<a href="https://github.com/Vishaldhaniya08/Sports-vs-Politics-Text-Classification" target="_blank">
View Source Code on GitHub
</a>
</p>
</div>

<footer>
<p>Â© 2026 Vishal | Natural Language Understanding Assignment</p>
</footer>

</div>

</body>
</html>






