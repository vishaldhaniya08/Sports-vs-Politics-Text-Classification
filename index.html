<!DOCTYPE html>
<html>
<head>
    <title>Sports vs Politics Text Classification</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>

<h1>Sports vs Politics Text Classification</h1>
<p><b>Author:</b> Vishal | Roll No: B23CM1048</p>

<hr>

<h2>ğŸ“Œ Abstract</h2>
<p>
This project investigates binary text classification for distinguishing between 
Sports and Politics news articles using classical machine learning techniques.
Two datasets were used: the BBC News dataset (clean and curated) and the AG News dataset 
(larger and more realistic). The objective was to evaluate model robustness across datasets 
and compare performance of Naive Bayes, Logistic Regression, and Support Vector Machine classifiers.
</p>

<hr>

<h2>ğŸ“‚ Data Collection</h2>
<p>
The BBC dataset was collected as structured folders containing text files categorized 
into Sports and Politics. The AG News dataset was downloaded in CSV format and filtered 
to include only World (relabelled as Politics) and Sports classes.
</p>

<ul>
<li><b>BBC Dataset:</b> 928 articles (511 Sports, 417 Politics)</li>
<li><b>AG News Dataset:</b> ~11,400 total filtered samples</li>
</ul>

<hr>

<h2>ğŸ“Š Dataset Characteristics</h2>
<p>
The BBC dataset contains longer, well-written articles with strong vocabulary separation 
between topics. In contrast, AG News articles are shorter, more diverse, and contain 
greater vocabulary overlap, making classification more challenging.
</p>

<hr>

<h2>âš™ï¸ Methodology</h2>
<p>
All text was converted to lowercase and English stopwords were removed. Documents were 
represented using TF-IDF (Term Frequency â€“ Inverse Document Frequency). 
An 80-20 stratified train-test split was applied to the BBC dataset, while AG News used 
predefined splits.
</p>

<p>
Three classifiers were implemented:
</p>
<ul>
<li>Naive Bayes</li>
<li>Logistic Regression</li>
<li>Support Vector Machine (Linear SVM)</li>
</ul>

<hr>

<h2>ğŸ“ˆ Experimental Results</h2>

<h3>BBC Dataset</h3>
<table border="1" cellpadding="8">
<tr><th>Model</th><th>Accuracy</th></tr>
<tr><td>Naive Bayes</td><td>1.000</td></tr>
<tr><td>Logistic Regression</td><td>1.000</td></tr>
<tr><td>SVM</td><td>1.000</td></tr>
</table>

<h3>AG News Dataset</h3>
<table border="1" cellpadding="8">
<tr><th>Model</th><th>Accuracy</th></tr>
<tr><td>Naive Bayes</td><td>0.9739</td></tr>
<tr><td>Logistic Regression</td><td>0.9774</td></tr>
<tr><td>SVM</td><td>0.9761</td></tr>
</table>

<hr>

<h2>ğŸ“Š Model Comparison Chart</h2>
<img src="assets/comparison_chart.png" width="700">

<hr>

<h2>ğŸ“‰ AG News Model Performance Chart</h2>
<img src="assets/ag_model_chart.png" width="700">

<hr>

<h2>ğŸ“‰ Confusion Matrix (AG News - Logistic Regression)</h2>
<img src="assets/confusion_matrix.png" width="500">

<hr>

<h2>ğŸ” Discussion</h2>
<p>
All models achieved perfect accuracy on the BBC dataset due to strong lexical separation 
between categories. However, performance slightly decreased on the AG News dataset 
(97â€“98%) because of vocabulary overlap and shorter context.
</p>

<p>
Logistic Regression performed marginally better, suggesting discriminative models 
handle noisy feature distributions more effectively.
</p>

<hr>

<h2>âš ï¸ Challenges Faced</h2>
<ul>
<li>Handling encoding issues in BBC dataset.</li>
<li>Relabeling AG News classes correctly.</li>
<li>Managing high-dimensional TF-IDF feature space.</li>
<li>Ensuring no data leakage during training/testing.</li>
</ul>

<hr>

<h2>ğŸš§ Limitations</h2>
<ul>
<li>TF-IDF ignores semantic meaning and word order.</li>
<li>Binary classification oversimplifies real-world news topics.</li>
<li>Models do not capture deep contextual understanding.</li>
<li>No deep learning models were explored.</li>
</ul>

<hr>

<h2>ğŸš€ Future Work</h2>
<ul>
<li>Use word embeddings (Word2Vec, GloVe).</li>
<li>Implement transformer-based models (BERT).</li>
<li>Extend to multi-class classification.</li>
<li>Apply cross-validation for robustness analysis.</li>
</ul>

<hr>

<h2>ğŸ“„ Full Report</h2>
<p>
<a href="report/Final_Report.pdf" target="_blank">Download Complete Report (PDF)</a>
</p>

<h2>ğŸ’» Source Code</h2>
<p>
<a href="https://github.com/yourusername/Sports-vs-Politics-Text-Classification" target="_blank">
View GitHub Repository
</a>
</p>

<hr>

<footer>
<p>Natural Language Understanding Assignment</p>
</footer>

</body>
</html>

